{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fd4dfc3",
   "metadata": {},
   "source": [
    "# Step-by-Step Implementation of GNN for Predicting Rice Prices\n",
    "\n",
    "This notebook demonstrates how to implement a Graph Neural Network (GNN) to predict rice prices for the next 30 days across 38 provinces in Indonesia. The model captures both temporal (time-based) and spatial (province-based) relationships.\n",
    "\n",
    "### Step 1: Prepare the Dataset\n",
    "1. Load the dataset `harga_beras_premium.csv`.\n",
    "2. Preprocess the data:\n",
    "   - Convert the `Tanggal` column to datetime format.\n",
    "   - Normalize the `Harga` column using `MinMaxScaler`.\n",
    "   - Create an adjacency matrix to represent spatial relationships between provinces.\n",
    "   - Generate a feature matrix for time-series data.\n",
    "\n",
    "### Step 2: Prepare Data for PyTorch Geometric\n",
    "1. Create an `edge_index` tensor to represent spatial connections.\n",
    "2. Use the time-series data as node features.\n",
    "3. Define the target as the last 30 days of prices.\n",
    "\n",
    "### Step 3: Define the Spatio-Temporal GCN Model\n",
    "1. Use two GCN layers to capture spatial relationships.\n",
    "2. Add a fully connected layer to capture temporal dependencies.\n",
    "\n",
    "### Step 4: Train the Model\n",
    "1. Use Mean Squared Error (MSE) as the loss function.\n",
    "2. Optimize the model using Adam optimizer.\n",
    "3. Train the model for a specified number of epochs.\n",
    "\n",
    "### Step 5: Make Predictions\n",
    "1. Use the trained model to predict rice prices for the next 30 days.\n",
    "2. Denormalize the predictions to get the actual prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cba6bc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7337/71002758.py:9: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['Tanggal'] = pd.to_datetime(df['Tanggal'])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Prepare the Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('harga_beras_premium.csv')\n",
    "df = df.dropna()  # Remove rows with missing values\n",
    "df['Tanggal'] = pd.to_datetime(df['Tanggal'])\n",
    "df.sort_values('Tanggal', inplace=True)\n",
    "\n",
    "# Normalize the price column\n",
    "scaler = MinMaxScaler()\n",
    "df['Harga'] = scaler.fit_transform(df[['Harga']])\n",
    "\n",
    "# Create adjacency matrix based on provinces\n",
    "provinces = df['Provinsi'].unique()\n",
    "province_index = {province: idx for idx, province in enumerate(provinces)}\n",
    "adj_matrix = np.zeros((len(provinces), len(provinces)))\n",
    "\n",
    "# Example: Connect provinces based on geographical proximity (simplified)\n",
    "for i in range(len(provinces)):\n",
    "    for j in range(len(provinces)):\n",
    "        if i != j:\n",
    "            adj_matrix[i, j] = 1  # Fully connected graph for simplicity\n",
    "\n",
    "# Ensure all time-series data have the same length\n",
    "min_length = min(len(df[df['Provinsi'] == province]['Harga'].values) for province in provinces)\n",
    "\n",
    "features = []\n",
    "for province in provinces:\n",
    "    province_data = df[df['Provinsi'] == province]['Harga'].values\n",
    "    if len(province_data) > min_length:\n",
    "        province_data = province_data[:min_length]  # Trim to minimum length\n",
    "    elif len(province_data) < min_length:\n",
    "        province_data = np.pad(province_data, (0, min_length - len(province_data)), 'constant')  # Pad with zeros\n",
    "    features.append(province_data)\n",
    "\n",
    "features = np.array(features).T  # Shape: (time_steps, num_provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46f1b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define the Spatio-Temporal GCN Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class SpatioTemporalGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SpatioTemporalGCN, self).__init__()\n",
    "        self.gcn1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.gcn2 = GCNConv(hidden_dim, output_dim)\n",
    "        self.fc = nn.Linear(output_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = features.shape[1]  # Number of provinces\n",
    "hidden_dim = 64\n",
    "output_dim = features.shape[1]  # Match the number of provinces (38)\n",
    "model = SpatioTemporalGCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7685ea5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 30 is out of bounds for dimension 0 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     44\u001b[39m model.train()\n\u001b[32m     45\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m loss = criterion(output, y)\n\u001b[32m     48\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mSpatioTemporalGCN.forward\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[32m     14\u001b[39m     x, edge_index = data.x, data.edge_index\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgcn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     x = torch.relu(x)\n\u001b[32m     17\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.gcn2(x, edge_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch_geometric/nn/conv/gcn_conv.py:108\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m    106\u001b[39m row, col = edge_index[\u001b[32m0\u001b[39m], edge_index[\u001b[32m1\u001b[39m]\n\u001b[32m    107\u001b[39m idx = col \u001b[38;5;28;01mif\u001b[39;00m flow == \u001b[33m'\u001b[39m\u001b[33msource_to_target\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m deg = \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m deg_inv_sqrt = deg.pow_(-\u001b[32m0.5\u001b[39m)\n\u001b[32m    110\u001b[39m deg_inv_sqrt.masked_fill_(deg_inv_sqrt == \u001b[38;5;28mfloat\u001b[39m(\u001b[33m'\u001b[39m\u001b[33minf\u001b[39m\u001b[33m'\u001b[39m), \u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Universitas Hasanuddin/Semester IV/Data Mining/prediksi_harga_pangan/env/lib64/python3.13/site-packages/torch_geometric/utils/_scatter.py:75\u001b[39m, in \u001b[36mscatter\u001b[39m\u001b[34m(src, index, dim, dim_size, reduce)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33msum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33madd\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     74\u001b[39m     index = broadcast(index, src, dim)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reduce == \u001b[33m'\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     78\u001b[39m     count = src.new_zeros(dim_size)\n",
      "\u001b[31mRuntimeError\u001b[39m: index 30 is out of bounds for dimension 0 with size 30"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from torch_geometric.data import Data\n",
    "import torch.optim as optim\n",
    "from torch_geometric.utils import add_self_loops\n",
    "\n",
    "# Prepare data for PyTorch Geometric\n",
    "edge_index = torch.tensor(np.array(np.nonzero(adj_matrix)), dtype=torch.long)\n",
    "x = torch.tensor(features[-30:], dtype=torch.float)  # Use only the last 30 days\n",
    "data = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "# Adjust edge_index to match the reduced input data (30 days)\n",
    "valid_nodes = list(range(x.size(0)))  # Nodes corresponding to the last 30 days\n",
    "edge_index = edge_index[:, (edge_index[0] < len(valid_nodes)) & (edge_index[1] < len(valid_nodes))]\n",
    "\n",
    "# Recalculate edge_index to ensure it matches valid nodes\n",
    "valid_indices = torch.arange(x.size(0))\n",
    "edge_index = edge_index[:, (edge_index[0] < valid_indices.size(0)) & (edge_index[1] < valid_indices.size(0))]\n",
    "\n",
    "# Remap edge_index to match valid nodes\n",
    "node_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(valid_nodes)}\n",
    "edge_index = torch.tensor(\n",
    "    [[node_mapping[node.item()] for node in edge_index[0] if node.item() in node_mapping],\n",
    "     [node_mapping[node.item()] for node in edge_index[1] if node.item() in node_mapping]],\n",
    "    dtype=torch.long\n",
    ")\n",
    "\n",
    "# Revalidate edge_index to ensure it matches valid nodes\n",
    "valid_edges = (edge_index[0] < len(valid_nodes)) & (edge_index[1] < len(valid_nodes))\n",
    "edge_index = edge_index[:, valid_edges]\n",
    "\n",
    "# Ensure edge_index matches valid nodes and add self-loops\n",
    "edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define target (last 30 days of prices)\n",
    "y = torch.tensor(features[-30:], dtype=torch.float)\n",
    "\n",
    "# Training loop\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa91ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make Predictions\n",
    "model.eval()\n",
    "predicted_prices = model(data).detach().numpy()\n",
    "predicted_prices = scaler.inverse_transform(predicted_prices)  # Denormalize\n",
    "\n",
    "# Print the predicted prices for the next 30 days\n",
    "print(\"Predicted Prices for the Next 30 Days:\", predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eef9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Evaluate the Model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, mape, r2\n",
    "\n",
    "# Denormalize the true values\n",
    "y_true = scaler.inverse_transform(y.numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "rmse, mae, mape, r2 = calculate_metrics(y_true, predicted_prices)\n",
    "\n",
    "# Print the results\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}%\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
